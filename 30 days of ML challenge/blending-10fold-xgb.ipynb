{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn import preprocessing\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:35:19.513553Z","iopub.execute_input":"2021-08-28T23:35:19.514202Z","iopub.status.idle":"2021-08-28T23:35:19.521348Z","shell.execute_reply.started":"2021-08-28T23:35:19.514157Z","shell.execute_reply":"2021-08-28T23:35:19.519877Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Load the data\n\nNext, we'll load the training and test data.  \n\nWe set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)","metadata":{}},{"cell_type":"code","source":"# Load the training data\ntrain = pd.read_csv(\"../input/train10fold/train-folds (1).csv\")\ntest = pd.read_csv(\"../input/30daysofml/test.csv\")\nsubmission_data = pd.read_csv(\"../input/30daysofmlsubmisison/sample_submission.csv\")\n# Preview the data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:23:19.602458Z","iopub.execute_input":"2021-08-28T23:23:19.602841Z","iopub.status.idle":"2021-08-28T23:23:21.422039Z","shell.execute_reply.started":"2021-08-28T23:23:19.602809Z","shell.execute_reply":"2021-08-28T23:23:21.420832Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont6     cont7  \\\n0   1    B    B    B    C    B    B    A    E    C  ...  0.160266  0.310921   \n1   2    B    B    A    A    B    D    A    F    A  ...  0.558922  0.516294   \n2   3    A    A    A    C    B    D    A    D    A  ...  0.375348  0.902567   \n3   4    B    B    A    C    B    D    A    E    C  ...  0.239061  0.732948   \n4   6    A    A    A    C    B    D    A    E    A  ...  0.420667  0.648182   \n\n      cont8     cont9    cont10    cont11    cont12    cont13    target  kfold  \n0  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850  8.113634      3  \n1  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083  8.481233      7  \n2  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846  8.364351      3  \n3  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682  8.049253      6  \n4  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823  7.972260      8  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>target</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.160266</td>\n      <td>0.310921</td>\n      <td>0.389470</td>\n      <td>0.267559</td>\n      <td>0.237281</td>\n      <td>0.377873</td>\n      <td>0.322401</td>\n      <td>0.869850</td>\n      <td>8.113634</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.558922</td>\n      <td>0.516294</td>\n      <td>0.594928</td>\n      <td>0.341439</td>\n      <td>0.906013</td>\n      <td>0.921701</td>\n      <td>0.261975</td>\n      <td>0.465083</td>\n      <td>8.481233</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>D</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.375348</td>\n      <td>0.902567</td>\n      <td>0.555205</td>\n      <td>0.843531</td>\n      <td>0.748809</td>\n      <td>0.620126</td>\n      <td>0.541474</td>\n      <td>0.763846</td>\n      <td>8.364351</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.239061</td>\n      <td>0.732948</td>\n      <td>0.679618</td>\n      <td>0.574844</td>\n      <td>0.346010</td>\n      <td>0.714610</td>\n      <td>0.540150</td>\n      <td>0.280682</td>\n      <td>8.049253</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.420667</td>\n      <td>0.648182</td>\n      <td>0.684501</td>\n      <td>0.956692</td>\n      <td>1.000773</td>\n      <td>0.776742</td>\n      <td>0.625849</td>\n      <td>0.250823</td>\n      <td>7.972260</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Separate target from features\nfeatures = [col for col in train.columns if col not in ('id', 'target', 'kfold')]\nobject_cols = [col for col in features if 'cat' in col]\n\nordinal_encoder = OrdinalEncoder()\n\nxtest = test[features]\nxtest = xtest.copy()\nxtest[object_cols] = ordinal_encoder.fit_transform(xtest[object_cols])","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:23:24.255205Z","iopub.execute_input":"2021-08-28T23:23:24.255586Z","iopub.status.idle":"2021-08-28T23:23:25.701835Z","shell.execute_reply.started":"2021-08-28T23:23:24.255554Z","shell.execute_reply":"2021-08-28T23:23:25.700612Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"final_valid_preds = {}\nfinal_test_preds = []\nrmse_score = []\nfor fold in range(10):\n    xtrain = train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n    \n    valid_ids = xvalid.id.values.tolist() # to keep all the ids of the validation data\n        \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n        \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    xtrain[object_cols]= ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.fit_transform(xvalid[object_cols])\n    \n    best_params = {'learning_rate': 0.07853392035787837,\n                     'colsample_bytree': 0.170759104940733,\n                     'max_depth': 3,\n                     'reg_lambda': 1.7549293092194938e-05,\n                     'reg_alpha': 14.68267919457715,\n                     'subsample': 0.8031450486786944,\n                     'alpha': 30\n                  }\n    model = XGBRegressor(objective='reg:squarederror',\n                         n_estimators=5000,\n                         random_state=0,\n                         **best_params,\n                         tree_method='gpu_hist',\n                         gpu_id=0, \n                         predictor='gpu_predictor'\n                        )\n\n    model.fit(xtrain, ytrain, \n              early_stopping_rounds=300, \n              eval_set=[(xvalid, yvalid)], \n              verbose=1000)\n    \n    valid_preds = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    \n    final_valid_preds.update(dict(zip(valid_ids, valid_preds)))\n    final_test_preds.append(test_preds)\n\n    rmse = mean_squared_error(yvalid, valid_preds, squared=False)\n    rmse_score.append(rmse)\n    print(fold, rmse)\n    \nprint(np.mean(rmse_score), np.std(rmse_score))\n\nfinal_valid_preds = pd.DataFrame.from_dict(final_valid_preds,orient='index').reset_index()\nfinal_valid_preds.columns = ['id', 'pred_1']\nfinal_valid_preds.to_csv('valid_pred1.csv', index=False)\n\nsubmission_data.target = np.mean(np.column_stack(final_test_preds), axis = 1)\nsubmission_data.columns = ['id', 'pred_1']\nsubmission_data.to_csv('test_pred1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:12:19.338463Z","iopub.execute_input":"2021-08-28T23:12:19.338914Z","iopub.status.idle":"2021-08-28T23:12:28.045282Z","shell.execute_reply.started":"2021-08-28T23:12:19.338870Z","shell.execute_reply":"2021-08-28T23:12:28.042545Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:7.17455\n[1000]\tvalidation_0-rmse:0.72290\n[2000]\tvalidation_0-rmse:0.72151\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-550d9c043cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m               \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m               verbose=1000)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mvalid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m         )\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataset name should not contain `-`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# into datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# split up `test-error:0.1234`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1567\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[1;32m   1570\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#model 2\nimport lightgbm as lgb\n\n\nfinal_valid_preds = {}\nfinal_test_preds = []\nrmse_score = []\nfor fold in range(10):\n    xtrain = train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n    \n    valid_ids = xvalid.id.values.tolist() # to keep all the ids of the validation data\n        \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n        \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    xtrain[object_cols]= ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.fit_transform(xvalid[object_cols])\n    \n    best_params = {'learning_rate': 0.07853392035787837,\n                     'colsample_bytree': 0.170759104940733,\n                     'max_depth': 3,\n                     'reg_lambda': 1.7549293092194938e-05,\n                     'reg_alpha': 14.68267919457715,\n                     'subsample': 0.8031450486786944,\n                     'alpha': 30\n                  }\n    model = lgb.LGBMRegressor(n_estimators=5000,\n                         random_state=0,\n                         **best_params,\n                         device='gpu')\n\n    model.fit(xtrain, ytrain, \n              early_stopping_rounds=300, \n              eval_set=[(xvalid, yvalid)], \n              verbose=1000)\n    \n    valid_preds = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    \n    final_valid_preds.update(dict(zip(valid_ids, valid_preds)))\n    final_test_preds.append(test_preds)\n\n    rmse = mean_squared_error(yvalid, valid_preds, squared=False)\n    rmse_score.append(rmse)\n    print(fold, rmse)\n    \nprint(np.mean(rmse_score), np.std(rmse_score))\n\nfinal_valid_preds = pd.DataFrame.from_dict(final_valid_preds,orient='index').reset_index()\nfinal_valid_preds.columns = ['id', 'pred_2']\nfinal_valid_preds.to_csv('valid_pred2.csv', index=False)\n\nsubmission_data.target = np.mean(np.column_stack(final_test_preds), axis = 1)\nsubmission_data.columns = ['id', 'pred_2']\nsubmission_data.to_csv('test_pred2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:23:37.562459Z","iopub.execute_input":"2021-08-28T23:23:37.563048Z","iopub.status.idle":"2021-08-28T23:35:19.511663Z","shell.execute_reply.started":"2021-08-28T23:23:37.562997Z","shell.execute_reply":"2021-08-28T23:35:19.510608Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.522734\n[2000]\tvalid_0's l2: 0.520559\n[3000]\tvalid_0's l2: 0.52022\nEarly stopping, best iteration is:\n[2967]\tvalid_0's l2: 0.520209\n0 0.7212550067667121\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.518351\n[2000]\tvalid_0's l2: 0.515797\n[3000]\tvalid_0's l2: 0.515298\nEarly stopping, best iteration is:\n[2992]\tvalid_0's l2: 0.51529\n1 0.7178373633743628\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.518059\n[2000]\tvalid_0's l2: 0.51555\n[3000]\tvalid_0's l2: 0.515118\nEarly stopping, best iteration is:\n[2952]\tvalid_0's l2: 0.515081\n2 0.7176913196792831\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.515027\n[2000]\tvalid_0's l2: 0.513042\nEarly stopping, best iteration is:\n[2485]\tvalid_0's l2: 0.512817\n3 0.7161121189696065\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.528252\n[2000]\tvalid_0's l2: 0.525516\n[3000]\tvalid_0's l2: 0.524993\nEarly stopping, best iteration is:\n[3384]\tvalid_0's l2: 0.524936\n4 0.7245279252822381\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.518847\n[2000]\tvalid_0's l2: 0.516447\n[3000]\tvalid_0's l2: 0.51607\n[4000]\tvalid_0's l2: 0.516071\nEarly stopping, best iteration is:\n[3757]\tvalid_0's l2: 0.516007\n5 0.718340210569739\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.517954\n[2000]\tvalid_0's l2: 0.515511\n[3000]\tvalid_0's l2: 0.515313\nEarly stopping, best iteration is:\n[2885]\tvalid_0's l2: 0.515233\n6 0.7177983002786967\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.511028\n[2000]\tvalid_0's l2: 0.508706\nEarly stopping, best iteration is:\n[2583]\tvalid_0's l2: 0.508466\n7 0.7130682709452598\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.51866\n[2000]\tvalid_0's l2: 0.516062\n[3000]\tvalid_0's l2: 0.515364\nEarly stopping, best iteration is:\n[3609]\tvalid_0's l2: 0.515231\n8 0.7177985796760998\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1224: UserWarning: predictor keyword has been found in `params` and will be ignored.\nPlease use predictor argument of the Dataset constructor to pass this parameter.\n  .format(key))\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Unknown parameter: predictor\n[LightGBM] [Warning] Unknown parameter: gpu_id\nTraining until validation scores don't improve for 300 rounds\n[1000]\tvalid_0's l2: 0.511396\n[2000]\tvalid_0's l2: 0.509107\n[3000]\tvalid_0's l2: 0.508447\nEarly stopping, best iteration is:\n[3376]\tvalid_0's l2: 0.508272\n9 0.7129318283875675\n0.7177360923929565 0.003261955631323601\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the training data\ntrain = pd.read_csv(\"../input/train10fold/train-folds (1).csv\")\ntest = pd.read_csv(\"../input/30daysofml/test.csv\")\n\n# Separate target from features\nfeatures = [col for col in train.columns if col not in ('id', 'target', 'kfold')]\nobject_cols = [col for col in features if 'cat' in col]\n\nordinal_encoder = OrdinalEncoder()\n\nxtest = test[features]\nxtest = xtest.copy()\nxtest[object_cols] = ordinal_encoder.fit_transform(xtest[object_cols])\n\n#model 3\nfrom catboost import CatBoostRegressor\n\nfinal_valid_preds = {}\nfinal_test_preds = []\nrmse_score = []\nfor fold in range(10):\n    xtrain = train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n    \n    valid_ids = xvalid.id.values.tolist() # to keep all the ids of the validation data\n        \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n        \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    xtrain[object_cols]= ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.fit_transform(xvalid[object_cols])\n    \n    best_params = {'learning_rate': 0.07853392035787837,\n                     'max_depth': 3,\n                     'reg_lambda': 1.7549293092194938e-05,\n                     'subsample': 0.8031450486786944\n                  }\n    model = CatBoostRegressor(iterations=200,\n                         random_state=0,\n                         **best_params,\n                         task_type='GPU',\n                         devices='0'\n                        )\n\n    model.fit(xtrain, ytrain, \n              early_stopping_rounds=300, \n              eval_set=[(xvalid, yvalid)], \n              verbose=1000)\n    \n    valid_preds = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    \n    final_valid_preds.update(dict(zip(valid_ids, valid_preds)))\n    final_test_preds.append(test_preds)\n\n    rmse = mean_squared_error(yvalid, valid_preds, squared=False)\n    rmse_score.append(rmse)\n    print(fold, rmse)\n    \nprint(np.mean(rmse_score), np.std(rmse_score))\n\nfinal_valid_preds = pd.DataFrame.from_dict(final_valid_preds,orient='index').reset_index()\nfinal_valid_preds.columns = ['id', 'pred_3']\nfinal_valid_preds.to_csv('valid_pred3.csv', index=False)\n\nsubmission_data.target = np.mean(np.column_stack(final_test_preds), axis = 1)\nsubmission_data.columns = ['id', 'pred_3']\nsubmission_data.to_csv('test_pred3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:15:09.797778Z","iopub.execute_input":"2021-08-29T00:15:09.798172Z","iopub.status.idle":"2021-08-29T00:15:59.745376Z","shell.execute_reply.started":"2021-08-29T00:15:09.798141Z","shell.execute_reply":"2021-08-29T00:15:59.744253Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"Custom logger is already specified. Specify more than one logger at same time is not thread safe.","output_type":"stream"},{"name":"stdout","text":"0:\tlearn: 0.7456224\ttest: 0.7487633\tbest: 0.7487633 (0)\ttotal: 6.94ms\tremaining: 1.38s\n199:\tlearn: 0.7323407\ttest: 0.7358480\tbest: 0.7358480 (199)\ttotal: 1.14s\tremaining: 0us\nbestTest = 0.7358479908\nbestIteration = 199\n0 0.7358479150269729\n0:\tlearn: 0.7459196\ttest: 0.7458535\tbest: 0.7458535 (0)\ttotal: 6.83ms\tremaining: 1.36s\n199:\tlearn: 0.7324704\ttest: 0.7332655\tbest: 0.7332655 (199)\ttotal: 1.13s\tremaining: 0us\nbestTest = 0.7332655405\nbestIteration = 199\n1 0.7332655658536577\n0:\tlearn: 0.7460566\ttest: 0.7444133\tbest: 0.7444133 (0)\ttotal: 6.67ms\tremaining: 1.33s\n199:\tlearn: 0.7323208\ttest: 0.7320975\tbest: 0.7320975 (199)\ttotal: 1.07s\tremaining: 0us\nbestTest = 0.7320975101\nbestIteration = 199\n2 0.732097571578492\n0:\tlearn: 0.7460805\ttest: 0.7441788\tbest: 0.7441788 (0)\ttotal: 7.16ms\tremaining: 1.43s\n199:\tlearn: 0.7331103\ttest: 0.7316573\tbest: 0.7316573 (199)\ttotal: 1.17s\tremaining: 0us\nbestTest = 0.7316572717\nbestIteration = 199\n3 0.7316573611236431\n0:\tlearn: 0.7448066\ttest: 0.7556985\tbest: 0.7556985 (0)\ttotal: 9.29ms\tremaining: 1.85s\n199:\tlearn: 0.7321488\ttest: 0.7416097\tbest: 0.7416097 (199)\ttotal: 1.13s\tremaining: 0us\nbestTest = 0.7416096654\nbestIteration = 199\n4 0.7416096852370236\n0:\tlearn: 0.7458657\ttest: 0.7467478\tbest: 0.7467478 (0)\ttotal: 6.69ms\tremaining: 1.33s\n199:\tlearn: 0.7327044\ttest: 0.7339629\tbest: 0.7339629 (199)\ttotal: 1.07s\tremaining: 0us\nbestTest = 0.7339629163\nbestIteration = 199\n5 0.733962889517355\n0:\tlearn: 0.7459094\ttest: 0.7457733\tbest: 0.7457733 (0)\ttotal: 6.38ms\tremaining: 1.27s\n199:\tlearn: 0.7330619\ttest: 0.7336046\tbest: 0.7336046 (199)\ttotal: 1.05s\tremaining: 0us\nbestTest = 0.7336045826\nbestIteration = 199\n6 0.7336046010788023\n0:\tlearn: 0.7464183\ttest: 0.7411373\tbest: 0.7411373 (0)\ttotal: 6.99ms\tremaining: 1.39s\n199:\tlearn: 0.7338690\ttest: 0.7289468\tbest: 0.7289468 (199)\ttotal: 1.13s\tremaining: 0us\nbestTest = 0.7289467823\nbestIteration = 199\n7 0.7289467991717492\n0:\tlearn: 0.7458525\ttest: 0.7470131\tbest: 0.7470131 (0)\ttotal: 6.46ms\tremaining: 1.28s\n199:\tlearn: 0.7325309\ttest: 0.7340667\tbest: 0.7340667 (199)\ttotal: 1.47s\tremaining: 0us\nbestTest = 0.7340666906\nbestIteration = 199\n8 0.7340667277749058\n0:\tlearn: 0.7465854\ttest: 0.7396086\tbest: 0.7396086 (0)\ttotal: 6.14ms\tremaining: 1.22s\n199:\tlearn: 0.7329839\ttest: 0.7274243\tbest: 0.7274243 (199)\ttotal: 1.03s\tremaining: 0us\nbestTest = 0.7274243097\nbestIteration = 199\n9 0.7274243318021164\n0.7332483448164717 0.003664085826963881\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:69: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the training data\ntrain = pd.read_csv(\"../input/train-kfolds/train-folds.csv\")\ntest = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsubmission_data = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n# Preview the data\ntrain.head()\n\n# Separate target from features\nfeatures = [col for col in train.columns if col not in ('id', 'target', 'kfold')]\nobject_cols = [col for col in features if 'cat' in col]\n\nordinal_encoder = OrdinalEncoder()\n\nxtest = test[features]\nxtest = xtest.copy()\nxtest[object_cols] = ordinal_encoder.fit_transform(xtest[object_cols])\n\n# standardization\nnumerical_cols = [col for col in train.columns if col.startswith('cont')]\n\nscaler = preprocessing.StandardScaler()\nxtest[numerical_cols] = scaler.fit_transform(xtest[numerical_cols])\n\n\nfinal_preds = []\nrmse_valid = []\nfor fold in range(5):\n    xtrain = train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    xtrain[object_cols]= ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.fit_transform(xvalid[object_cols])\n    \n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.fit_transform(xvalid[numerical_cols])\n    \n    \n    model = XGBRegressor(colsample_bytree=0.2,\n                         learning_rate=0.6,max_depth=4, alpha=30,\n                         n_estimators=200, tree_method='gpu_hist',\n                         gpu_id=0, predictor='gpu_predictor')\n\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_preds.append(test_preds)\n    \n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    rmse_valid.append(rmse)\n    print(fold, rmse)\n    \nprint(np.mean(rmse_valid), np.std(rmse_valid))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Model 3\n\n# Load the training data\ntrain = pd.read_csv(\"../input/train10fold/train-folds (1).csv\")\ntest = pd.read_csv(\"../input/30daysofml/test.csv\")\nsubmission_data = pd.read_csv(\"../input/30daysofmlsubmisison/sample_submission.csv\")\n\n# Separate target from features\nfeatures = [col for col in train.columns if col not in ('id', 'target', 'kfold')]\n# Separate object columns from features\nobject_cols = [col for col in features if 'cat' in col]\n# Separate numerical columns from the features\nnumerical_cols = [col for col in train.columns if col.startswith('cont')]\n\n\noneHotEnc = preprocessing.OneHotEncoder(sparse=False, handle_unknown='ignore')\n\nxtest = test[features]\nxtest = xtest.copy()\nxtest_ohe = oneHotEnc.fit_transform(xtest[object_cols])\nxtest_ohe = pd.DataFrame(xtest_ohe, columns=[f'ohe_{i}' for i\n                                             in range(xtest_ohe.shape[1])])\nxtest = pd.concat([xtest, xtest_ohe], axis = 1)\nxtest = xtest.drop(object_cols, axis = 1)\n\nscaler = preprocessing.StandardScaler()\nxtest = scaler.fit_transform(xtest)\n\nfinal_valid_preds = {}\nfinal_test_preds = []\nrmse_score = []\nfor fold in range(10):\n    xtrain = train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n    \n    valid_ids = xvalid.id.values.tolist() # to keep all the ids of the validation data\n        \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n        \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    xtrain_ohe= oneHotEnc.fit_transform(xtrain[object_cols])\n    xvalid_ohe = oneHotEnc.transform(xvalid[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f'ohe_{i}' for i\n                                             in range(xtrain_ohe.shape[1])])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f'ohe_{i}' for i\n                                             in range(xvalid_ohe.shape[1])])\n    \n    xtrain = pd.concat([xtrain, xtrain_ohe], axis = 1)\n    xvalid = pd.concat([xvalid, xvalid_ohe], axis = 1)\n    \n    xtrain = xtrain.drop(object_cols, axis = 1)\n    xvalid = xvalid.drop(object_cols, axis = 1)\n    \n    xtrain = scaler.fit_transform(xtrain)\n    xvalid = scaler.transform(xvalid)\n    \n    best_params = {'learning_rate': 0.07853392035787837,\n                     'colsample_bytree': 0.170759104940733,\n                     'max_depth': 3,\n                     'reg_lambda': 1.7549293092194938e-05,\n                     'reg_alpha': 14.68267919457715,\n                     'subsample': 0.8031450486786944,\n                     'alpha': 30\n                  }\n    model = XGBRegressor(objective='reg:squarederror',\n                         n_estimators=5000,\n                         random_state=0,\n                         **best_params,\n                         tree_method='gpu_hist',\n                         gpu_id=0, \n                         predictor='gpu_predictor'\n                        )\n\n    model.fit(xtrain, ytrain, \n              early_stopping_rounds=300, \n              eval_set=[(xvalid, yvalid)], \n              verbose=1000)\n    \n    valid_preds = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    \n    final_valid_preds.update(dict(zip(valid_ids, valid_preds)))\n    final_test_preds.append(test_preds)\n\n    rmse = mean_squared_error(yvalid, valid_preds, squared=False)\n    rmse_score.append(rmse)\n    print(fold, rmse)\n    \nprint(np.mean(rmse_score), np.std(rmse_score))\n\nfinal_valid_preds = pd.DataFrame.from_dict(final_valid_preds,orient='index').reset_index()\nfinal_valid_preds.columns = ['id', 'pred_3']\nfinal_valid_preds.to_csv('valid_pred3.csv', index=False)\n\nsubmission_data.target = np.mean(np.column_stack(final_test_preds), axis = 1)\nsubmission_data.columns = ['id', 'pred_3']\nsubmission_data.to_csv('test_pred3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:19:20.068150Z","iopub.execute_input":"2021-08-29T00:19:20.068542Z","iopub.status.idle":"2021-08-29T00:21:57.767135Z","shell.execute_reply.started":"2021-08-29T00:19:20.068509Z","shell.execute_reply":"2021-08-29T00:21:57.766056Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:7.17455\n[1000]\tvalidation_0-rmse:0.72301\n[2000]\tvalidation_0-rmse:0.72151\n[2784]\tvalidation_0-rmse:0.72136\n0 0.7213148461565618\n[0]\tvalidation_0-rmse:7.16555\n[1000]\tvalidation_0-rmse:0.71977\n[2000]\tvalidation_0-rmse:0.71808\n[3000]\tvalidation_0-rmse:0.71777\n[3163]\tvalidation_0-rmse:0.71781\n1 0.71774507954462\n[0]\tvalidation_0-rmse:7.17125\n[1000]\tvalidation_0-rmse:0.71940\n[2000]\tvalidation_0-rmse:0.71775\n[2879]\tvalidation_0-rmse:0.71750\n2 0.7174274006019555\n[0]\tvalidation_0-rmse:7.17485\n[1000]\tvalidation_0-rmse:0.71797\n[2000]\tvalidation_0-rmse:0.71682\n[2613]\tvalidation_0-rmse:0.71684\n3 0.7167750349291848\n[0]\tvalidation_0-rmse:7.17640\n[1000]\tvalidation_0-rmse:0.72627\n[2000]\tvalidation_0-rmse:0.72432\n[3000]\tvalidation_0-rmse:0.72396\n[3622]\tvalidation_0-rmse:0.72389\n4 0.7238720665529246\n[0]\tvalidation_0-rmse:7.17319\n[1000]\tvalidation_0-rmse:0.72032\n[2000]\tvalidation_0-rmse:0.71859\n[3000]\tvalidation_0-rmse:0.71828\n[3173]\tvalidation_0-rmse:0.71830\n5 0.7182100358864684\n[0]\tvalidation_0-rmse:7.17617\n[1000]\tvalidation_0-rmse:0.71963\n[2000]\tvalidation_0-rmse:0.71791\n[3000]\tvalidation_0-rmse:0.71765\n[3499]\tvalidation_0-rmse:0.71771\n6 0.7175970152299739\n[0]\tvalidation_0-rmse:7.16656\n[1000]\tvalidation_0-rmse:0.71460\n[2000]\tvalidation_0-rmse:0.71305\n[2883]\tvalidation_0-rmse:0.71283\n7 0.7127300104727923\n[0]\tvalidation_0-rmse:7.17376\n[1000]\tvalidation_0-rmse:0.72004\n[2000]\tvalidation_0-rmse:0.71835\n[3000]\tvalidation_0-rmse:0.71795\n[3572]\tvalidation_0-rmse:0.71793\n8 0.717893426559574\n[0]\tvalidation_0-rmse:7.17702\n[1000]\tvalidation_0-rmse:0.71516\n[2000]\tvalidation_0-rmse:0.71362\n[3000]\tvalidation_0-rmse:0.71321\n[3775]\tvalidation_0-rmse:0.71323\n9 0.7131589041319589\n0.7176723820066014 0.003125960613934821\n","output_type":"stream"}]},{"cell_type":"code","source":"#Model 4\n# Load the training data\ntrain = pd.read_csv(\"../input/train10fold/train-folds (1).csv\")\ntest = pd.read_csv(\"../input/30daysofml/test.csv\")\nsubmission_data = pd.read_csv(\"../input/30daysofmlsubmisison/sample_submission.csv\")\n\n# Separate target from features\nfeatures = [col for col in train.columns if col not in ('id', 'target', 'kfold')]\n# Separate object columns from features\nobject_cols = [col for col in features if 'cat' in col]\n# Separate numerical columns from the features\nnumerical_cols = [col for col in train.columns if col.startswith('cont')]\n\n\noneHotEnc = preprocessing.OneHotEncoder(sparse=False, handle_unknown='ignore')\n\nxtest = test[features]\nxtest = xtest.copy()\nxtest_ohe = oneHotEnc.fit_transform(xtest[object_cols])\nxtest_ohe = pd.DataFrame(xtest_ohe, columns=[f'ohe_{i}' for i\n                                             in range(xtest_ohe.shape[1])])\nxtest = pd.concat([xtest, xtest_ohe], axis = 1)\nxtest = xtest.drop(object_cols, axis = 1)\n\n#scaler = preprocessing.StandardScaler()\n#xtest = scaler.fit_transform(xtest)\n\nfinal_valid_preds = {}\nfinal_test_preds = []\nrmse_score = []\nfor fold in range(10):\n    xtrain = train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n    \n    valid_ids = xvalid.id.values.tolist() # to keep all the ids of the validation data\n        \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n        \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    xtrain_ohe= oneHotEnc.fit_transform(xtrain[object_cols])\n    xvalid_ohe = oneHotEnc.transform(xvalid[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f'ohe_{i}' for i\n                                             in range(xtrain_ohe.shape[1])])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f'ohe_{i}' for i\n                                             in range(xvalid_ohe.shape[1])])\n    \n    xtrain = pd.concat([xtrain, xtrain_ohe], axis = 1)\n    xvalid = pd.concat([xvalid, xvalid_ohe], axis = 1)\n    \n    xtrain = xtrain.drop(object_cols, axis = 1)\n    xvalid = xvalid.drop(object_cols, axis = 1)\n    \n    best_params = {'learning_rate': 0.07853392035787837,\n                     'colsample_bytree': 0.170759104940733,\n                     'max_depth': 3,\n                     'reg_lambda': 1.7549293092194938e-05,\n                     'reg_alpha': 14.68267919457715,\n                     'subsample': 0.8031450486786944,\n                     'alpha': 30\n                  }\n    model = XGBRegressor(objective='reg:squarederror',\n                         n_estimators=5000,\n                         random_state=0,\n                         **best_params,\n                         tree_method='gpu_hist',\n                         gpu_id=0, \n                         predictor='gpu_predictor'\n                        )\n\n    model.fit(xtrain, ytrain, \n              early_stopping_rounds=300, \n              eval_set=[(xvalid, yvalid)], \n              verbose=1000)\n    \n    valid_preds = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    \n    final_valid_preds.update(dict(zip(valid_ids, valid_preds)))\n    final_test_preds.append(test_preds)\n\n    rmse = mean_squared_error(yvalid, valid_preds, squared=False)\n    rmse_score.append(rmse)\n    print(fold, rmse)\n    \nprint(np.mean(rmse_score), np.std(rmse_score))\n\nfinal_valid_preds = pd.DataFrame.from_dict(final_valid_preds,orient='index').reset_index()\nfinal_valid_preds.columns = ['id', 'pred_4']\nfinal_valid_preds.to_csv('valid_pred4.csv', index=False)\n\nsubmission_data.target = np.mean(np.column_stack(final_test_preds), axis = 1)\nsubmission_data.columns = ['id', 'pred_4']\nsubmission_data.to_csv('test_pred4.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:06:47.504026Z","iopub.execute_input":"2021-08-29T00:06:47.504420Z","iopub.status.idle":"2021-08-29T00:09:22.430275Z","shell.execute_reply.started":"2021-08-29T00:06:47.504387Z","shell.execute_reply":"2021-08-29T00:09:22.428830Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:7.17455\n[1000]\tvalidation_0-rmse:0.72301\n[2000]\tvalidation_0-rmse:0.72154\n[3000]\tvalidation_0-rmse:0.72136\n[3084]\tvalidation_0-rmse:0.72135\n0 0.7213187453491325\n[0]\tvalidation_0-rmse:7.16555\n[1000]\tvalidation_0-rmse:0.71973\n[2000]\tvalidation_0-rmse:0.71803\n[2848]\tvalidation_0-rmse:0.71778\n1 0.7177792843575497\n[0]\tvalidation_0-rmse:7.17125\n[1000]\tvalidation_0-rmse:0.71949\n[2000]\tvalidation_0-rmse:0.71779\n[2945]\tvalidation_0-rmse:0.71754\n2 0.7174973968392352\n[0]\tvalidation_0-rmse:7.17485\n[1000]\tvalidation_0-rmse:0.71800\n[2000]\tvalidation_0-rmse:0.71682\n[2150]\tvalidation_0-rmse:0.71688\n3 0.7167809030107852\n[0]\tvalidation_0-rmse:7.17640\n[1000]\tvalidation_0-rmse:0.72632\n[2000]\tvalidation_0-rmse:0.72444\n[3000]\tvalidation_0-rmse:0.72410\n[3451]\tvalidation_0-rmse:0.72407\n4 0.724044439569008\n[0]\tvalidation_0-rmse:7.17319\n[1000]\tvalidation_0-rmse:0.72032\n[2000]\tvalidation_0-rmse:0.71863\n[3000]\tvalidation_0-rmse:0.71834\n[3204]\tvalidation_0-rmse:0.71834\n5 0.7182868281001097\n[0]\tvalidation_0-rmse:7.17617\n[1000]\tvalidation_0-rmse:0.71966\n[2000]\tvalidation_0-rmse:0.71786\n[3000]\tvalidation_0-rmse:0.71764\n[3499]\tvalidation_0-rmse:0.71771\n6 0.7176107094614887\n[0]\tvalidation_0-rmse:7.16656\n[1000]\tvalidation_0-rmse:0.71460\n[2000]\tvalidation_0-rmse:0.71301\n[2988]\tvalidation_0-rmse:0.71275\n7 0.7127204068402092\n[0]\tvalidation_0-rmse:7.17376\n[1000]\tvalidation_0-rmse:0.72010\n[2000]\tvalidation_0-rmse:0.71827\n[3000]\tvalidation_0-rmse:0.71785\n[3467]\tvalidation_0-rmse:0.71787\n8 0.7178323676241785\n[0]\tvalidation_0-rmse:7.17702\n[1000]\tvalidation_0-rmse:0.71517\n[2000]\tvalidation_0-rmse:0.71370\n[3000]\tvalidation_0-rmse:0.71331\n[3179]\tvalidation_0-rmse:0.71332\n9 0.7132952736923703\n0.7177166354844068 0.003143316089233989\n","output_type":"stream"}]},{"cell_type":"code","source":"#create new train dataset from valid predictions\ndf = pd.read_csv('../input/train10fold/train-folds (1).csv')\ndf_test = pd.read_csv('../input/30daysofml/test.csv')\nsubmission_data = pd.read_csv('../input/30daysofmlsubmisison/sample_submission.csv')\n\ndf1 = pd.read_csv('./valid_pred1.csv')\ndf2 = pd.read_csv('./valid_pred2.csv')\ndf3 = pd.read_csv('./valid_pred3.csv')\ndf4 = pd.read_csv('./valid_pred4.csv')\n\ndf_test1 = pd.read_csv('./test_pred1.csv')\ndf_test2 = pd.read_csv('./test_pred2.csv')\ndf_test3 = pd.read_csv('./test_pred3.csv')\ndf_test4 = pd.read_csv('./test_pred4.csv')\n\ndf = df.merge(df1, on='id', how='left')\ndf = df.merge(df1, on='id', how='left')\ndf = df.merge(df1, on='id', how='left')\ndf = df.merge(df1, on='id', how='left')\n\ndf_test = df_test.merge(df_test1, on='id', how='left')\ndf_test = df_test.merge(df_test2, on='id', how='left')\ndf_test = df_test.merge(df_test3, on='id', how='left')\ndf_test = df_test.merge(df_test4, on='id', how='left')\n\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = ['pred1', 'pred2', 'pred3', 'pred4']\ndf_test = df_test[useful_features]\n\nx_test = df_test.copy()\n\nfinal_preds = []\nrmse_score = []\nfor fold in range(10):\n    xtrain = train[train.kfold != fold].reset_index(drop=True)\n    xvalid = train[train.kfold == fold].reset_index(drop=True)\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n        \n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n    \n    xtrain[object_cols]= ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.fit_transform(xvalid[object_cols])\n    \n    best_params = {'learning_rate': 0.07853392035787837,\n                     'max_depth': 3,\n                     'subsample': 0.8031450486786944,\n                     'alpha': 0.9\n                  }\n    model = LinearRegression(random_state=0)\n    model.fit(xtrain, ytrain)\n    \n    valid_preds = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_preds.append(test_preds)\n\n    rmse = mean_squared_error(yvalid, valid_preds, squared=False)\n    rmse_score.append(rmse)\n    print(fold, rmse)\n    \nprint(np.mean(rmse_score), np.std(rmse_score))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data.target = np.mean(np.column_stack(final_preds), axis = 1)\nsubmission_data.columns = ['id', 'pred_4']\nsubmission_data.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}