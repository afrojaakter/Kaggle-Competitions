{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background:#2b6684\">\n</div>\n           ","metadata":{}},{"cell_type":"markdown","source":"### Song Popularity Prediction || EDA 1\n1. \n2. ","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#2b4444;font-family:'Times';font-size:35px;color:  #F0CB8E\" >&ensp;Song Popularity Prediction || EDA1  \n</div>\n<div class=\"alert alert-warning\" role=\"alert\">\n<ul style=\"font-family:cursive;font-size:18px\" >\n    \n<li><a href = \"#1\"> 1. Introduction </a></li>     \n<li ><a href = \"#2\"> 2. Preparations </a></li> \n<ul>\n<li ><a  href = \"#200\"> 2.1 Load Libraries </a></li>\n<li ><a  href = \"#201\"> 2.2 Load Data </a></li>\n</ul>\n<li><a href = \"#3\"> 3. Overview: structure and data content</a></li>\n<ul> \n<li  ><a href = \"#300\">3.1 Look at the data</a></li>\n<li  ><a href = \"#301\">3.2 Missing Values</a></li>\n</ul>  \n<li ><a  href = \"#4\"> 4. Visualisation - Individual features </a></li>\n<ul> \n<li  ><a href = \"#400\">4.1 Predictor features</a></li>\n<li  ><a href = \"#401\">4.2 Target: Song Popularity</a></li>\n</ul>  \n\n<li ><a  href = \"#5\"> 5. Feature interactions</a></li>\n<ul>\n<li ><a  href = \"#500\"> 5.1 Target impact</a></li>\n<li ><a  href = \"#501\"> 5.2 Feature-Feature interaction (correlation)</a></li>\n<li ><a  href = \"#502\"> 5.3 Feature-target interactions</a></li>\n    </ul></ul>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"[<p style=\"font-family:cursive;font-size:18px; color:#A20404\">back to Table of Contents</p>](#table-of-contents)\n<a id=\"1\"></a>\n\n<div style=\"background:#2b6684   ;font-family:'Times';font-size:35px;color:  #F0CB8E\" >&ensp;Introduction</div>\n<div class=\"alert alert-warning\" role=\"alert\">\n<ul style=\"font-family:cursive;font-size:18px; color:#A20404\" >\n<li>Welcome to one of the first Kaggle Community Competitions in the world!</li>\n<li>This challenge is about predicting Song Popularity based on a set of different features.</li>\n<li>This specific competition is about predicting Song Popularity based on a set of different features. It is positioned as the first in a series of starter competitions that provide a gentle introduction to machine learning (ML) and data science (DS). This is a classification challenge, with the evaluation metric being chosen as <a style=\"color:  blue\" href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\" target=\"_blank\"><u>AUC</u></a></li>\n<li>The data consists of the standard Kaggle train.csv and test.csv files, with a sample_submission.csv to show you the structure of the file that should be submitted.</li>\n<li>Checkout more about Data: <a style=\"color:  blue\" href=\"https://www.kaggle.com/c/song-popularity-prediction/discussion/301616\" target=\"_blank\"> <u>Data Dictionary</u></a> by <a style=\"color:  blue\" href=\"https://www.kaggle.com/remekkinas\" target=\"_blank\"> <u>Remek Kinas</u></a></li>   \n   \n<li>This notebook started out as a live-coding session on Abhishek Thakurâ€™s channel on Youtube:<a style=\"color:  blue\" href=\"https://www.youtube.com/watch?v=JXF-7rCcR1c\" target=\"_blank\"> <u>Link to the Youtube Video</u></a> </li>","metadata":{}},{"cell_type":"markdown","source":"<div style ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport optuna\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport lightgbm as lgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-24T18:50:41.487220Z","iopub.execute_input":"2022-01-24T18:50:41.487555Z","iopub.status.idle":"2022-01-24T18:50:44.857408Z","shell.execute_reply.started":"2022-01-24T18:50:41.487520Z","shell.execute_reply":"2022-01-24T18:50:44.856463Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/song-popularity-prediction/train.csv', index_col = 'id')\ndf_test = pd.read_csv('../input/song-popularity-prediction/test.csv', index_col = 'id')\ndf_train.shape, df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:44.859628Z","iopub.execute_input":"2022-01-24T18:50:44.860889Z","iopub.status.idle":"2022-01-24T18:50:45.177960Z","shell.execute_reply.started":"2022-01-24T18:50:44.860841Z","shell.execute_reply":"2022-01-24T18:50:45.176914Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.179539Z","iopub.execute_input":"2022-01-24T18:50:45.180030Z","iopub.status.idle":"2022-01-24T18:50:45.206823Z","shell.execute_reply.started":"2022-01-24T18:50:45.179964Z","shell.execute_reply":"2022-01-24T18:50:45.205912Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.209448Z","iopub.execute_input":"2022-01-24T18:50:45.209979Z","iopub.status.idle":"2022-01-24T18:50:45.229875Z","shell.execute_reply.started":"2022-01-24T18:50:45.209930Z","shell.execute_reply":"2022-01-24T18:50:45.229186Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.230932Z","iopub.execute_input":"2022-01-24T18:50:45.231682Z","iopub.status.idle":"2022-01-24T18:50:45.241420Z","shell.execute_reply.started":"2022-01-24T18:50:45.231644Z","shell.execute_reply":"2022-01-24T18:50:45.240522Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='song_popularity', data = df_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.244463Z","iopub.execute_input":"2022-01-24T18:50:45.245370Z","iopub.status.idle":"2022-01-24T18:50:45.469632Z","shell.execute_reply.started":"2022-01-24T18:50:45.245318Z","shell.execute_reply":"2022-01-24T18:50:45.468662Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"categorical_cols = ['key', 'audio_mode', 'time_signature']\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.471604Z","iopub.execute_input":"2022-01-24T18:50:45.472002Z","iopub.status.idle":"2022-01-24T18:50:45.476853Z","shell.execute_reply.started":"2022-01-24T18:50:45.471925Z","shell.execute_reply":"2022-01-24T18:50:45.475392Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### missing values\nLet's combine the test and train data to see the distribution of missing values in the whole dateset. ","metadata":{}},{"cell_type":"code","source":"#combine train and test data together to deal with missing values\ndf_train['isTrain'] = True\ndf_test['isTrain'] = False\ntt = pd.concat([df_train, df_test]).reset_index(drop=True).copy()\ndf_train.shape, df_test.shape, tt.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.478820Z","iopub.execute_input":"2022-01-24T18:50:45.479579Z","iopub.status.idle":"2022-01-24T18:50:45.523136Z","shell.execute_reply.started":"2022-01-24T18:50:45.479527Z","shell.execute_reply":"2022-01-24T18:50:45.521889Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tt.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.524896Z","iopub.execute_input":"2022-01-24T18:50:45.525129Z","iopub.status.idle":"2022-01-24T18:50:45.548220Z","shell.execute_reply.started":"2022-01-24T18:50:45.525101Z","shell.execute_reply":"2022-01-24T18:50:45.547247Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tt.tail()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.551042Z","iopub.execute_input":"2022-01-24T18:50:45.551635Z","iopub.status.idle":"2022-01-24T18:50:45.580637Z","shell.execute_reply.started":"2022-01-24T18:50:45.551583Z","shell.execute_reply":"2022-01-24T18:50:45.579804Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"list(tt.columns)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.582106Z","iopub.execute_input":"2022-01-24T18:50:45.582869Z","iopub.status.idle":"2022-01-24T18:50:45.589373Z","shell.execute_reply.started":"2022-01-24T18:50:45.582831Z","shell.execute_reply":"2022-01-24T18:50:45.588791Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Before we start, we should ask why there is missing values in the data. \nexamples could be,\n1. Sensor data where the sensor went offline\n2. Survey data where some answeres were not answered\n3. A kaggle competition where the host wants to make the problem hard\nSometimes values being null itself is a indicator to help out with the modeling technique. It could be the values are radomly missing or the fact that they missing could be a feature itself. \n\nLet's see the missing value counts in train vs. test","metadata":{}},{"cell_type":"code","source":"df_train.isna()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.590855Z","iopub.execute_input":"2022-01-24T18:50:45.591324Z","iopub.status.idle":"2022-01-24T18:50:45.625618Z","shell.execute_reply.started":"2022-01-24T18:50:45.591291Z","shell.execute_reply":"2022-01-24T18:50:45.624803Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_test.isna()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.626943Z","iopub.execute_input":"2022-01-24T18:50:45.627186Z","iopub.status.idle":"2022-01-24T18:50:45.656177Z","shell.execute_reply.started":"2022-01-24T18:50:45.627155Z","shell.execute_reply":"2022-01-24T18:50:45.655198Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.657992Z","iopub.execute_input":"2022-01-24T18:50:45.658446Z","iopub.status.idle":"2022-01-24T18:50:45.669529Z","shell.execute_reply.started":"2022-01-24T18:50:45.658395Z","shell.execute_reply":"2022-01-24T18:50:45.668559Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df_test.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.672190Z","iopub.execute_input":"2022-01-24T18:50:45.673204Z","iopub.status.idle":"2022-01-24T18:50:45.683507Z","shell.execute_reply.started":"2022-01-24T18:50:45.673149Z","shell.execute_reply":"2022-01-24T18:50:45.682350Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"We see in both train and test data, there are some features with missing values and some without. \n\nNow we want to see is there any diffirenct between the null values in the trian and test data in the dataset","metadata":{}},{"cell_type":"code","source":"#creating a dataframe with null values in the test and train dataset\nncounts = pd.DataFrame([df_train.isna().mean(), df_test.isna().mean()]).T\nncounts = ncounts.rename(columns={0: 'train_missing', 1: 'test_missing'})\nncounts","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.685532Z","iopub.execute_input":"2022-01-24T18:50:45.685835Z","iopub.status.idle":"2022-01-24T18:50:45.707834Z","shell.execute_reply.started":"2022-01-24T18:50:45.685801Z","shell.execute_reply":"2022-01-24T18:50:45.706992Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# filter out the non-missing features and \n# plot the features with missing vlaues only\nncounts.query('train_missing > 0').plot(kind='barh',\n                                        figsize=(8,5), \n                                        title='%of missing values')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:50:45.709151Z","iopub.execute_input":"2022-01-24T18:50:45.709384Z","iopub.status.idle":"2022-01-24T18:50:46.030779Z","shell.execute_reply.started":"2022-01-24T18:50:45.709357Z","shell.execute_reply":"2022-01-24T18:50:46.030057Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"This is very interesting that all the features in both in trian and test data, approximately 10% of the data is missing. This is worth more exploration and thinking\n\n","metadata":{}},{"cell_type":"code","source":"nacols = ['song_duration_ms',\n         'acousticness',\n         'danceability',\n         'energy',\n         'instrumentalness',\n         'key',\n         'liveness',\n         'loudness']","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:56:32.200870Z","iopub.execute_input":"2022-01-24T18:56:32.201200Z","iopub.status.idle":"2022-01-24T18:56:32.205543Z","shell.execute_reply.started":"2022-01-24T18:56:32.201167Z","shell.execute_reply":"2022-01-24T18:56:32.204669Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### How many missing values per observations/example","metadata":{}},{"cell_type":"code","source":"# counts of null per row/example\ndf_train.isna().sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:55:57.082620Z","iopub.execute_input":"2022-01-24T18:55:57.083457Z","iopub.status.idle":"2022-01-24T18:55:57.097073Z","shell.execute_reply.started":"2022-01-24T18:55:57.083393Z","shell.execute_reply":"2022-01-24T18:55:57.096232Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"tt['n_missing'] = tt[nacols].isna().sum(axis=1)\ndf_train['n_missing'] = df_train[nacols].isna().sum(axis=1)\ndf_test['n_missing'] = df_test[nacols].isna().sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:57:58.341012Z","iopub.execute_input":"2022-01-24T18:57:58.341529Z","iopub.status.idle":"2022-01-24T18:57:58.357086Z","shell.execute_reply.started":"2022-01-24T18:57:58.341492Z","shell.execute_reply":"2022-01-24T18:57:58.356020Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"tt['n_missing']","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:58:33.293074Z","iopub.execute_input":"2022-01-24T18:58:33.293755Z","iopub.status.idle":"2022-01-24T18:58:33.301411Z","shell.execute_reply.started":"2022-01-24T18:58:33.293700Z","shell.execute_reply":"2022-01-24T18:58:33.300784Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# how many of the samples has 0 misisng values, 1 missing values and so on\ntt['n_missing'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:58:25.200856Z","iopub.execute_input":"2022-01-24T18:58:25.201336Z","iopub.status.idle":"2022-01-24T18:58:25.209280Z","shell.execute_reply.started":"2022-01-24T18:58:25.201303Z","shell.execute_reply":"2022-01-24T18:58:25.208646Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"we see that most of our samples has no missing values, 18880 samples has 1 missing values, 7421 samples has 2 missing values and so on. This make sence since only 10% of the data is missing in this dataset","metadata":{}},{"cell_type":"code","source":"tt['n_missing'].value_counts().plot(kind='bar',\n                                   title='Number of Missing Valeus per Sample')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:01:35.452592Z","iopub.execute_input":"2022-01-24T19:01:35.452986Z","iopub.status.idle":"2022-01-24T19:01:35.688784Z","shell.execute_reply.started":"2022-01-24T19:01:35.452944Z","shell.execute_reply":"2022-01-24T19:01:35.687771Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"tt.query('n_missing == 6') # samples with 6 missing values","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:02:39.311163Z","iopub.execute_input":"2022-01-24T19:02:39.311498Z","iopub.status.idle":"2022-01-24T19:02:39.341169Z","shell.execute_reply.started":"2022-01-24T19:02:39.311459Z","shell.execute_reply":"2022-01-24T19:02:39.340127Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"We see two of these sample are from training data and one from test data. There is actually real sparcity of features that could be used to predict the song popularity of these examples.Imputation will take a real big toll in these examples in particular","metadata":{}},{"cell_type":"markdown","source":"### Is there an imbalance in missing values when splitting by other features?\nOne thing we can check that we have some categorical features and we have our target feature. Are there any imbalance in missing values between these grouping? Let's look at the binary feature 'audio mode'.","metadata":{}},{"cell_type":"code","source":"tt['audio_mode'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:09:57.165777Z","iopub.execute_input":"2022-01-24T19:09:57.166821Z","iopub.status.idle":"2022-01-24T19:09:57.175445Z","shell.execute_reply.started":"2022-01-24T19:09:57.166771Z","shell.execute_reply":"2022-01-24T19:09:57.174796Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"cat_features = ['key', 'audio_mode']\ntt.groupby('audio_mode')['n_missing'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:12:51.790581Z","iopub.execute_input":"2022-01-24T19:12:51.791282Z","iopub.status.idle":"2022-01-24T19:12:51.805467Z","shell.execute_reply.started":"2022-01-24T19:12:51.791224Z","shell.execute_reply":"2022-01-24T19:12:51.804625Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"we about 80% in audio mode 0 and about 80% in audio mode 1 has missing values.which is pretty even. Now let's look at time signature","metadata":{}},{"cell_type":"code","source":"tt.groupby('time_signature')['n_missing'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:14:49.215191Z","iopub.execute_input":"2022-01-24T19:14:49.215541Z","iopub.status.idle":"2022-01-24T19:14:49.228404Z","shell.execute_reply.started":"2022-01-24T19:14:49.215506Z","shell.execute_reply":"2022-01-24T19:14:49.227569Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Again pretty similar. Might be little bit of deviation here. Let's see with aggregated mean with count","metadata":{}},{"cell_type":"code","source":"tt.groupby('time_signature')['n_missing'].agg(['mean', 'count'])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:15:27.722533Z","iopub.execute_input":"2022-01-24T19:15:27.722911Z","iopub.status.idle":"2022-01-24T19:15:27.738096Z","shell.execute_reply.started":"2022-01-24T19:15:27.722872Z","shell.execute_reply":"2022-01-24T19:15:27.737275Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"The mean value might be lower but we see there so diffirent with the count with time signature 2 and 5.","metadata":{}},{"cell_type":"markdown","source":"### Prep - Create tag columns with missing indicators","metadata":{}},{"cell_type":"code","source":"# creating a dataframe with na cols as binary true or false\ntt_missing_tag_df = tt[nacols].isna() \n#  feature name + missing added with it\ntt_missing_tag_df.columns = [f\"{c}_missing\" for c in tt_missing_tag_df]","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:34:28.960323Z","iopub.execute_input":"2022-01-24T19:34:28.960916Z","iopub.status.idle":"2022-01-24T19:34:28.989332Z","shell.execute_reply.started":"2022-01-24T19:34:28.960850Z","shell.execute_reply":"2022-01-24T19:34:28.988583Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"tt_missing_tag_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:34:30.387275Z","iopub.execute_input":"2022-01-24T19:34:30.387595Z","iopub.status.idle":"2022-01-24T19:34:30.402450Z","shell.execute_reply.started":"2022-01-24T19:34:30.387564Z","shell.execute_reply":"2022-01-24T19:34:30.401428Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"list(tt_missing_tag_df.columns)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:36:46.190514Z","iopub.execute_input":"2022-01-24T19:36:46.190883Z","iopub.status.idle":"2022-01-24T19:36:46.198138Z","shell.execute_reply.started":"2022-01-24T19:36:46.190843Z","shell.execute_reply":"2022-01-24T19:36:46.197235Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#concat these dataframe with the existing dataframe\ntt= pd.concat([tt, tt_missing_tag_df], axis =1)\ntt.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:34:33.613332Z","iopub.execute_input":"2022-01-24T19:34:33.613658Z","iopub.status.idle":"2022-01-24T19:34:33.651744Z","shell.execute_reply.started":"2022-01-24T19:34:33.613625Z","shell.execute_reply":"2022-01-24T19:34:33.650954Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"tt.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:40:26.979601Z","iopub.execute_input":"2022-01-24T19:40:26.979991Z","iopub.status.idle":"2022-01-24T19:40:26.987155Z","shell.execute_reply.started":"2022-01-24T19:40:26.979950Z","shell.execute_reply":"2022-01-24T19:40:26.986331Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"### Protip: Try to predict the target using only missing value indicators as features","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.metrics import roc_auc_score\n\nlr = LogisticRegressionCV(scoring='accuracy')\nX = tt.query('isTrain')[\n    ['song_duration_ms_missing',\n     'acousticness_missing',\n     'danceability_missing',\n     'energy_missing',\n     'instrumentalness_missing',\n     'key_missing',\n     'liveness_missing',\n     'loudness_missing']\n]\ny = tt.query('isTrain')['song_popularity']\nlr.fit(X, y)\nlr.socre(X, y)\npreds = lr.predict_proba(X)[:, 0]\nroc_auc_score(y, preds)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T19:41:40.754760Z","iopub.execute_input":"2022-01-24T19:41:40.755117Z","iopub.status.idle":"2022-01-24T19:41:40.796285Z","shell.execute_reply.started":"2022-01-24T19:41:40.755080Z","shell.execute_reply":"2022-01-24T19:41:40.794807Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}